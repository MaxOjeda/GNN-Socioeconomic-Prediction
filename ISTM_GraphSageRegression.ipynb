{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "from utils import filling, kmeans_clustering, plot_clusters, get_feature_propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[355936, 6], edge_index=[2, 673565], edge_attributes=[673565, 2], comuna=[355936], ismt=[355936], lat=[355936], lon=[355936])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.5074, -1.1100, -1.6402,  1.2143,  1.6439,  1.6780],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([-33.4416, -33.4420, -33.4429,  ..., -33.4390, -33.4389, -33.4386])\n",
      "tensor([39., 39., 39.,  ..., 42., 42., 42.])\n",
      "tensor([0.8805, 0.8805, 0.8594,  ..., 0.8625, 0.8625, 0.8625])\n",
      "tensor([[     0,      1,      2,  ..., 355934, 355935, 355935],\n",
      "        [  4463,   4467,    488,  ..., 191461, 251187,   7949]])\n",
      "tensor([[80.8500,  5.8000],\n",
      "        [18.8300,  1.3000],\n",
      "        [16.0600,  1.1000],\n",
      "        ...,\n",
      "        [33.0400,  4.1000],\n",
      "        [ 2.5300,  0.2000],\n",
      "        [ 6.4800,  0.6000]])\n"
     ]
    }
   ],
   "source": [
    "data = torch.load('Data/santiago_zero_ismt.pt')\n",
    "data.comuna = data.x[:, 8]\n",
    "data.ismt = data.x[:,-1]\n",
    "data.lat = data.x[:,0]\n",
    "data.lon = data.x[:,1]\n",
    "data.x = data.x[:, 2:8]\n",
    "print(data)\n",
    "print(data.x)\n",
    "print(data.lat)\n",
    "print(data.comuna)\n",
    "print(data.ismt)\n",
    "print(data.edge_index)\n",
    "print(data.edge_attributes)\n",
    "\n",
    "data.ismt = data.ismt.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature filling\n",
      "tensor([[-1.8762,  0.0880,  1.8812, -0.7552, -2.0797, -1.2788],\n",
      "        [ 0.2155, -0.1407, -0.2000,  0.7840,  0.9977,  0.7484],\n",
      "        [ 0.0507, -1.1760, -0.3934,  1.3322,  0.4679,  0.7087],\n",
      "        ...,\n",
      "        [ 1.0445, -1.0450, -1.3092,  1.1516,  1.1633,  1.0873],\n",
      "        [ 1.5074, -1.1100, -1.6402,  1.2143,  1.6439,  1.6780],\n",
      "        [ 1.2992, -0.1245, -1.1497,  0.2336,  1.0391,  0.9675]])\n",
      "Feature filling completed. It took: 1.96s\n"
     ]
    }
   ],
   "source": [
    "data.x = get_feature_propagation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 284748\n",
      "Validation set length: 35594\n",
      "Test set length: 35594\n"
     ]
    }
   ],
   "source": [
    "index_list = data.edge_index.flatten().unique().tolist()\n",
    "\n",
    "# Porcentaje de índices para cada conjunto\n",
    "train_percentage = 0.8\n",
    "val_percentage = 0.1\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "train_index, remaining_index = train_test_split(index_list, train_size=train_percentage, random_state=42)\n",
    "\n",
    "# Dividir el resto en conjuntos de validación y prueba\n",
    "val_index, test_index = train_test_split(remaining_index, train_size=val_percentage / (1 - train_percentage), random_state=42)\n",
    "\n",
    "print(\"Training set length:\", len(train_index))\n",
    "print(\"Validation set length:\", len(val_index))\n",
    "print(\"Test set length:\", len(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes, n_features = data.x.shape\n",
    "\n",
    "train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[train_index] = True\n",
    "val_mask[val_index] = True\n",
    "test_mask[test_index] = True\n",
    "data['train_mask'] = train_mask\n",
    "data['val_mask'] = val_mask\n",
    "data['test_mask'] = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, dataset, num_layers, hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(dataset.num_features, hidden)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for i in range(num_layers - 1):\n",
    "            self.convs.append(SAGEConv(hidden, hidden))\n",
    "        self.lin1 = Linear(hidden, hidden)\n",
    "        self.lin2 = Linear(hidden, dataset.num_classes)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.7789, Val MSE: 0.2667\n",
      "Epoch: 002, Train Loss: 0.4343, Val MSE: 0.2194\n",
      "Epoch: 003, Train Loss: 0.3784, Val MSE: 0.2475\n",
      "Epoch: 004, Train Loss: 0.3892, Val MSE: 0.2123\n",
      "Epoch: 005, Train Loss: 0.3342, Val MSE: 0.1423\n",
      "Epoch: 006, Train Loss: 0.2460, Val MSE: 0.0851\n",
      "Epoch: 007, Train Loss: 0.1758, Val MSE: 0.0658\n",
      "Epoch: 008, Train Loss: 0.1458, Val MSE: 0.0748\n",
      "Epoch: 009, Train Loss: 0.1474, Val MSE: 0.0848\n",
      "Epoch: 010, Train Loss: 0.1501, Val MSE: 0.0835\n",
      "Epoch: 011, Train Loss: 0.1442, Val MSE: 0.0749\n",
      "Epoch: 012, Train Loss: 0.1290, Val MSE: 0.0660\n",
      "Epoch: 013, Train Loss: 0.1151, Val MSE: 0.0588\n",
      "Epoch: 014, Train Loss: 0.1050, Val MSE: 0.0533\n",
      "Epoch: 015, Train Loss: 0.0968, Val MSE: 0.0509\n",
      "Epoch: 016, Train Loss: 0.0917, Val MSE: 0.0513\n",
      "Epoch: 017, Train Loss: 0.0907, Val MSE: 0.0521\n",
      "Epoch: 018, Train Loss: 0.0899, Val MSE: 0.0505\n",
      "Epoch: 019, Train Loss: 0.0857, Val MSE: 0.0462\n",
      "Epoch: 020, Train Loss: 0.0792, Val MSE: 0.0413\n",
      "Epoch: 021, Train Loss: 0.0709, Val MSE: 0.0385\n",
      "Epoch: 022, Train Loss: 0.0650, Val MSE: 0.0393\n",
      "Epoch: 023, Train Loss: 0.0633, Val MSE: 0.0426\n",
      "Epoch: 024, Train Loss: 0.0643, Val MSE: 0.0460\n",
      "Epoch: 025, Train Loss: 0.0661, Val MSE: 0.0470\n",
      "Epoch: 026, Train Loss: 0.0657, Val MSE: 0.0452\n",
      "Epoch: 027, Train Loss: 0.0631, Val MSE: 0.0419\n",
      "Epoch: 028, Train Loss: 0.0601, Val MSE: 0.0389\n",
      "Epoch: 029, Train Loss: 0.0566, Val MSE: 0.0375\n",
      "Epoch: 030, Train Loss: 0.0554, Val MSE: 0.0376\n",
      "Epoch: 031, Train Loss: 0.0554, Val MSE: 0.0384\n",
      "Epoch: 032, Train Loss: 0.0560, Val MSE: 0.0388\n",
      "Epoch: 033, Train Loss: 0.0559, Val MSE: 0.0383\n",
      "Epoch: 034, Train Loss: 0.0550, Val MSE: 0.0374\n",
      "Epoch: 035, Train Loss: 0.0532, Val MSE: 0.0366\n",
      "Epoch: 036, Train Loss: 0.0515, Val MSE: 0.0364\n",
      "Epoch: 037, Train Loss: 0.0503, Val MSE: 0.0369\n",
      "Epoch: 038, Train Loss: 0.0501, Val MSE: 0.0375\n",
      "Epoch: 039, Train Loss: 0.0499, Val MSE: 0.0377\n",
      "Epoch: 040, Train Loss: 0.0502, Val MSE: 0.0374\n",
      "Epoch: 041, Train Loss: 0.0495, Val MSE: 0.0367\n",
      "Epoch: 042, Train Loss: 0.0485, Val MSE: 0.0358\n",
      "Epoch: 043, Train Loss: 0.0475, Val MSE: 0.0352\n",
      "Epoch: 044, Train Loss: 0.0469, Val MSE: 0.0351\n",
      "Epoch: 045, Train Loss: 0.0468, Val MSE: 0.0353\n",
      "Epoch: 046, Train Loss: 0.0469, Val MSE: 0.0355\n",
      "Epoch: 047, Train Loss: 0.0468, Val MSE: 0.0354\n",
      "Epoch: 048, Train Loss: 0.0463, Val MSE: 0.0352\n",
      "Epoch: 049, Train Loss: 0.0455, Val MSE: 0.0350\n",
      "Epoch: 050, Train Loss: 0.0452, Val MSE: 0.0351\n",
      "Test MSE: 0.0351\n"
     ]
    }
   ],
   "source": [
    "class GraphSageRegression(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSageRegression, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "# Model\n",
    "in_features = data.x.shape[1]\n",
    "hidden_features = 64\n",
    "out_features = 1\n",
    "model = GraphSageRegression(in_features, hidden_features, out_features)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train_model(model, data, mask):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)[mask]\n",
    "    loss = criterion(out, data.ismt[mask].view(-1, 1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_model(model, data, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(data.x, data.edge_index)[mask]\n",
    "        mse = criterion(pred, data.ismt[mask].view(-1, 1))\n",
    "    return mse.item()\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model(model, data, data.train_mask)\n",
    "    val_mse = evaluate_model(model, data, data.val_mask)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train Loss: {train_loss:.4f}, Val MSE: {val_mse:.4f}')\n",
    "\n",
    "test_mse = evaluate_model(model, data, data.test_mask)\n",
    "print(f'Test MSE: {test_mse:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
