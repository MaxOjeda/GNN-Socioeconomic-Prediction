{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "from utils import filling, kmeans_clustering, plot_clusters, get_feature_propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[355936, 6], edge_index=[2, 673565], edge_attributes=[673565, 2], comuna=[355936], y=[355936], lat=[355936], lon=[355936])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.5074, -1.1100, -1.6402,  1.2143,  1.6439,  1.6780],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([-33.4416, -33.4420, -33.4429,  ..., -33.4390, -33.4389, -33.4386])\n",
      "tensor([39., 39., 39.,  ..., 42., 42., 42.])\n",
      "tensor([0.0889, 0.0889, 0.1629,  ..., 0.1620, 0.1620, 0.1620])\n",
      "tensor([[     0,      1,      2,  ..., 355934, 355935, 355935],\n",
      "        [  4463,   4467,    488,  ..., 191461, 251187,   7949]])\n",
      "tensor([[80.8500,  5.8000],\n",
      "        [18.8300,  1.3000],\n",
      "        [16.0600,  1.1000],\n",
      "        ...,\n",
      "        [33.0400,  4.1000],\n",
      "        [ 2.5300,  0.2000],\n",
      "        [ 6.4800,  0.6000]])\n"
     ]
    }
   ],
   "source": [
    "data = torch.load('Data/santiago_zero_ismt.pt')\n",
    "data.comuna = data.x[:, 8]\n",
    "data.y = data.x[:,-2]\n",
    "data.lat = data.x[:,0]\n",
    "data.lon = data.x[:,1]\n",
    "data.x = data.x[:, 2:8]\n",
    "print(data)\n",
    "print(data.x)\n",
    "print(data.lat)\n",
    "print(data.comuna)\n",
    "print(data.y)\n",
    "print(data.edge_index)\n",
    "print(data.edge_attributes)\n",
    "\n",
    "data.y = data.y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature filling\n",
      "tensor([[-1.8762,  0.0880,  1.8812, -0.7552, -2.0797, -1.2788],\n",
      "        [ 0.2155, -0.1407, -0.2000,  0.7840,  0.9977,  0.7484],\n",
      "        [ 0.0507, -1.1760, -0.3934,  1.3322,  0.4679,  0.7087],\n",
      "        ...,\n",
      "        [ 1.0445, -1.0450, -1.3092,  1.1516,  1.1633,  1.0873],\n",
      "        [ 1.5074, -1.1100, -1.6402,  1.2143,  1.6439,  1.6780],\n",
      "        [ 1.2992, -0.1245, -1.1497,  0.2336,  1.0391,  0.9675]])\n",
      "Feature filling completed. It took: 2.02s\n"
     ]
    }
   ],
   "source": [
    "data.x = get_feature_propagation(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 284748\n",
      "Test set length: 71188\n"
     ]
    }
   ],
   "source": [
    "index_list = data.edge_index.flatten().unique().tolist()\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "train_index, test_index = train_test_split(index_list, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dividir el resto en conjuntos de validación y prueba\n",
    "print(\"Training set length:\", len(train_index))\n",
    "print(\"Test set length:\", len(test_index))\n",
    "\n",
    "\n",
    "n_nodes, n_features = data.x.shape\n",
    "\n",
    "train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[train_index] = True\n",
    "test_mask[test_index] = True\n",
    "data['train_mask'] = train_mask\n",
    "data['test_mask'] = test_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Val, Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 284748\n",
      "Validation set length: 35594\n",
      "Test set length: 35594\n"
     ]
    }
   ],
   "source": [
    "index_list = data.edge_index.flatten().unique().tolist()\n",
    "\n",
    "# Porcentaje de índices para cada conjunto\n",
    "train_percentage = 0.8\n",
    "val_percentage = 0.1\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "train_index, remaining_index = train_test_split(index_list, train_size=train_percentage, random_state=42)\n",
    "\n",
    "# Dividir el resto en conjuntos de validación y prueba\n",
    "val_index, test_index = train_test_split(remaining_index, train_size=val_percentage / (1 - train_percentage), random_state=42)\n",
    "\n",
    "print(\"Training set length:\", len(train_index))\n",
    "print(\"Validation set length:\", len(val_index))\n",
    "print(\"Test set length:\", len(test_index))\n",
    "\n",
    "n_nodes, n_features = data.x.shape\n",
    "\n",
    "train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[train_index] = True\n",
    "val_mask[val_index] = True\n",
    "test_mask[test_index] = True\n",
    "data['train_mask'] = train_mask\n",
    "data['val_mask'] = val_mask\n",
    "data['test_mask'] = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = torch.cat((data.x, data.y.unsqueeze(1), data.train_mask.unsqueeze(1), data.test_mask.unsqueeze(1)), dim=1)\n",
    "df_ismt = pd.DataFrame(data_tensor.numpy(), columns=['beautiful','boring','depressing','lively','safe','wealthy',\n",
    "                                                     'pct_hog40p', 'train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = df_ismt[df_ismt.train == 1]\n",
    "test_split = df_ismt[df_ismt.test == 1]\n",
    "\n",
    "X_train, y_train = train_split[['beautiful','boring','depressing','lively','safe','wealthy']], train_split.pct_hog40p\n",
    "X_test, y_test = test_split[['beautiful','boring','depressing','lively','safe','wealthy']], test_split.pct_hog40p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0564\n",
      "Mean Absolute Error: 0.2046\n",
      "R2 Score: 0.1067\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "mse_error = mean_squared_error(y_test, y_pred)\n",
    "mae_error = mean_absolute_error(y_test, y_pred)\n",
    "r2_score_error = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_error:.4f}\")\n",
    "print(f\"Mean Absolute Error: {mae_error:.4f}\")\n",
    "print(f\"R2 Score: {r2_score_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0694\n",
      "Mean Absolute Error: 0.1779\n",
      "R2 Score: -0.0985\n",
      "CPU times: total: 3.38 s\n",
      "Wall time: 8.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reg = DecisionTreeRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "mse_error = mean_squared_error(y_test, y_pred)\n",
    "mae_error = mean_absolute_error(y_test, y_pred)\n",
    "r2_score_error = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_error:.4f}\")\n",
    "print(f\"Mean Absolute Error: {mae_error:.4f}\")\n",
    "print(f\"R2 Score: {r2_score_error:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
